import { NextResponse } from "next/server"
import { createClient } from "@/lib/supabase/server"

// í”Œë«í¼ë³„ ìµœì í™” í•¨ìˆ˜
function optimizeForPlatform(baseContent: string, platform: string): { text: string; hashtags: string[] } {
  const hashtags: string[] = []

  switch (platform) {
    case "threads":
      // Threads: 300ì ì´ë‚´, ìºì£¼ì–¼, 2-3ê°œ í•´ì‹œíƒœê·¸, ì´ëª¨ì§€ í™œìš©
      const threadsText = baseContent.slice(0, 280) + (baseContent.length > 280 ? "..." : "")
      return {
        text: threadsText + " âœ¨",
        hashtags: ["#ë§ˆì¼€íŒ…ìë™í™”", "#AIì½˜í…ì¸ "],
      }

    case "linkedin":
      // LinkedIn: 1300ì ì´ë‚´, ì „ë¬¸ì , ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸
      const linkedinText = baseContent.slice(0, 1280) + (baseContent.length > 1280 ? "..." : "")
      return {
        text: linkedinText + "\n\nğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ì„ ìœ„í•œ ìŠ¤ë§ˆíŠ¸í•œ ì„ íƒ",
        hashtags: ["#ë§ˆì¼€íŒ…", "#AI", "#ë¹„ì¦ˆë‹ˆìŠ¤ìë™í™”", "#ë””ì§€í„¸ë§ˆì¼€íŒ…"],
      }

    case "x":
      // X.com: 280ì ì´ë‚´, ê°„ê²°í•˜ê³  ì„íŒ©íŠ¸
      const xText = baseContent.slice(0, 260) + (baseContent.length > 260 ? "..." : "")
      return {
        text: xText,
        hashtags: ["#AI", "#ë§ˆì¼€íŒ…"],
      }

    default:
      return { text: baseContent, hashtags: [] }
  }
}

// AI ì½˜í…ì¸  ìƒì„± í•¨ìˆ˜ (Ollama ì‚¬ìš©)
async function generateWithOllama(prompt: string, model: string = "qwen2.5:7b"): Promise<string> {
  try {
    const response = await fetch("http://localhost:11434/api/generate", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        model,
        prompt,
        stream: false,
      }),
    })

    if (!response.ok) {
      throw new Error(`Ollama API error: ${response.statusText}`)
    }

    const data = await response.json()
    return data.response || ""
  } catch (error) {
    console.error("Ollama generation error:", error)
    throw error
  }
}

export async function POST(request: Request) {
  try {
    const supabase = await createClient()

    // ì‚¬ìš©ì ì¸ì¦ í™•ì¸
    const { data: { user }, error: authError } = await supabase.auth.getUser()
    if (authError || !user) {
      return NextResponse.json({ error: "ì¸ì¦ í•„ìš”" }, { status: 401 })
    }

    const { productInfo, count, platforms, aiModel } = await request.json()

    if (!productInfo || !count || !platforms || platforms.length === 0) {
      return NextResponse.json({ error: "í•„ìˆ˜ ì •ë³´ ëˆ„ë½" }, { status: 400 })
    }

    if (count < 1 || count > 50) {
      return NextResponse.json({ error: "ìƒì„± ê°œìˆ˜ëŠ” 1-50 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤" }, { status: 400 })
    }

    // AI ëª¨ë¸ ê¸°ë³¸ê°’ ì„¤ì •
    const selectedModel = aiModel || "qwen2.5:7b"

    // ì‚¬ìš©ìì˜ ì²« ë²ˆì§¸ ë¸Œëœë“œ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ìƒì„±)
    const { data: brands } = await supabase
      .from("brands")
      .select("id")
      .eq("user_id" as any, user.id)
      .limit(1)

    let brandId: string
    if (!brands || brands.length === 0) {
      const { data: newBrand, error: brandError } = await supabase
        .from("brands")
        .insert({
          user_id: user.id,
          name: "ê¸°ë³¸ ë¸Œëœë“œ",
          description: "ìë™ ìƒì„±ëœ ë¸Œëœë“œ",
        })
        .select("id")
        .single()

      if (brandError || !newBrand) {
        return NextResponse.json({ error: "ë¸Œëœë“œ ìƒì„± ì‹¤íŒ¨" }, { status: 500 })
      }
      brandId = newBrand.id
    } else {
      brandId = brands[0].id
    }

    const contents = []

    // ì¼ê´„ ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬)
    const generationPromises = Array.from({ length: count }, async (_, index) => {
      try {
        const prompt = `ë‹¤ìŒ ì œí’ˆ/ì„œë¹„ìŠ¤ì— ëŒ€í•œ ë§ˆì¼€íŒ… ì½˜í…ì¸ ë¥¼ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ë§¤ë²ˆ ë‹¤ë¥¸ ê°ë„ì™€ ë©”ì‹œì§€ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ì œí’ˆ ì •ë³´: ${productInfo}

ì½˜í…ì¸  ë²ˆí˜¸: ${index + 1}/${count}

ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ëŠ” ì½˜í…ì¸ ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
1. ë§¤ë ¥ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” ë©”ì‹œì§€
2. ì œí’ˆì˜ í•µì‹¬ ê°€ì¹˜ ì „ë‹¬
3. íƒ€ê²Ÿ ê³ ê°ì˜ ë¬¸ì œ í•´ê²° ê°•ì¡°
4. ëª…í™•í•œ í–‰ë™ ìœ ë„ (CTA)
5. 200-300ì ë¶„ëŸ‰
6. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±

IMPORTANT: ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”. ì˜ì–´ë‚˜ ì¤‘êµ­ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ì½˜í…ì¸ ë§Œ ì‘ì„±í•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.`

        const aiContent = await generateWithOllama(prompt, selectedModel)

        // í”Œë«í¼ë³„ ìµœì í™”
        const platformVariations: any = {}
        platforms.forEach((platform: string) => {
          const optimized = optimizeForPlatform(aiContent, platform)
          platformVariations[platform] = {
            text: optimized.text,
            hashtags: optimized.hashtags,
          }
        })

        // DBì— ì €ì¥
        const { data: savedContent, error: saveError } = await supabase
          .from("contents")
          .insert({
            brand_id: brandId,
            title: `ìë™ ìƒì„± ì½˜í…ì¸  #${index + 1}`,
            body: aiContent,
            platform_variations: platformVariations,
            ai_model: selectedModel,
            status: "draft",
          })
          .select()
          .single()

        if (saveError) {
          console.error("Save error:", saveError)
          return {
            success: false,
            error: "ì €ì¥ ì‹¤íŒ¨",
            index: index + 1,
            aiModel: selectedModel,
          }
        }

        return {
          success: true,
          body: aiContent,
          platforms,
          contentId: savedContent.id,
          index: index + 1,
          aiModel: selectedModel,
        }
      } catch (error: any) {
        console.error(`Generation error for content ${index + 1}:`, error)
        return {
          success: false,
          error: error.message || "ìƒì„± ì‹¤íŒ¨",
          index: index + 1,
          aiModel: selectedModel,
        }
      }
    })

    // ëª¨ë“  ìƒì„± ì‘ì—… ëŒ€ê¸°
    const results = await Promise.all(generationPromises)

    const successCount = results.filter((r) => r.success).length
    const failCount = results.filter((r) => !r.success).length

    return NextResponse.json({
      success: true,
      contents: results,
      summary: {
        total: count,
        success: successCount,
        failed: failCount,
      },
    })
  } catch (error: any) {
    console.error("Bulk generate error:", error)
    return NextResponse.json(
      { error: error.message || "ì¼ê´„ ìƒì„± ì‹¤íŒ¨" },
      { status: 500 }
    )
  }
}
